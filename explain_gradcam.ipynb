{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89871cb7-7e8c-4e82-81fe-6cd3aad637fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openslide\n",
    "import torch\n",
    "from datasets.dataset_h5 import eval_transforms\n",
    "from models.model_clam import CLAM_MB\n",
    "from models.resnet_custom_grad import resnet50_baseline\n",
    "from torch.autograd import grad\n",
    "from torchvision import models, transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc4c1ac2-388f-40de-8932-9d2782e3b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=7):\n",
    "    import random\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # if device.type == \"cuda\":\n",
    "    #     torch.cuda.manual_seed(seed)\n",
    "    #     torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c6b8629-3f42-44bf-ba41-9e1b48c8baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_model(ckpt_path):\n",
    "\n",
    "    model = CLAM_MB(dropout=True, n_classes=6, subtyping=True)\n",
    "\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    ckpt_clean = {}\n",
    "    for key in ckpt.keys():\n",
    "        if \"instance_loss_fn\" in key:\n",
    "            continue\n",
    "        ckpt_clean.update({key.replace(\".module\", \"\"): ckpt[key]})\n",
    "    model.load_state_dict(ckpt_clean, strict=True)\n",
    "\n",
    "    model.relocate()\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4215cb4-253f-455b-9655-2a701fa07005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initiate_model(\"/home/jupyter/CLAM/results/disorder_tau_j_s1/s_0_checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "199229af-b98b-43c6-a5d7-bd26f1dd726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet50_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0fd0169-6767-4f52-ad77-999b656661bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "toTensor = transforms.ToTensor()\n",
    "normalize = transforms.Normalize(mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95831a40-d108-436d-a95d-7f01221ed13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(\n",
    "    resnet,\n",
    "    model,\n",
    "    slide_name,\n",
    "    target_idx,\n",
    "    features_dir,\n",
    "    slide_dir,\n",
    "    target_label=0,\n",
    "    full_pipeline=False,\n",
    "):\n",
    "    # load features\n",
    "    target_features_path = os.path.join(features_dir, \"{}.h5\".format(slide_name))\n",
    "    with h5py.File(target_features_path, \"r\") as hdf5_file:\n",
    "        features = hdf5_file[\"features\"][:]\n",
    "        coords = hdf5_file[\"coords\"][:]\n",
    "    features = torch.from_numpy(features).cuda()\n",
    "\n",
    "    # grab targeted tile from wsi\n",
    "    target_coords = coords[target_idx]\n",
    "    target_coords_x, target_coords_y = target_coords\n",
    "    print(target_coords_x, target_coords_y)\n",
    "    target_slide_path = os.path.join(slide_dir, \"{}.svs\".format(slide_name))\n",
    "    wsi = openslide.open_slide(target_slide_path)\n",
    "    target_tile = wsi.read_region(\n",
    "        (target_coords_x, target_coords_y), 0, (256, 256)\n",
    "    ).convert(\"RGB\")\n",
    "    # display(target_tile)\n",
    "    target_tile = toTensor(target_tile)\n",
    "    target_tile = normalize(target_tile).unsqueeze(0)\n",
    "    # pass image through resnet\n",
    "\n",
    "    y = resnet(target_tile)\n",
    "\n",
    "    # replace target feature and pass through model, if needed\n",
    "    if not full_pipeline:\n",
    "        l, y, y1, a, r = model(y)\n",
    "        print(l.shape)\n",
    "\n",
    "    # back prop and grab target gradient\n",
    "    loss_metric = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    target_label = torch.Tensor([target_label]).long()\n",
    "    loss = loss_metric(y, target_label)\n",
    "    loss.backward()\n",
    "\n",
    "    gradients = resnet.grad\n",
    "    # print(grad.shape)\n",
    "\n",
    "    activations = resnet.get_activation(target_tile).detach()\n",
    "    # print(activation.shape)\n",
    "    # generate explaination heatmap\n",
    "\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "    for i in range(512):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "    heatmap /= torch.max(heatmap)\n",
    "\n",
    "    heatmap.squeeze()\n",
    "    img = wsi.read_region((target_coords_x, target_coords_y), 0, (256, 256)).convert(\n",
    "        \"RGB\"\n",
    "    )\n",
    "    img = np.array(img)\n",
    "    print(img.shape)\n",
    "    heatmap = cv2.resize(np.float32(heatmap), (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = 0.4 * heatmap + 0.6 * img\n",
    "    cv2.imwrite(\"/home/jupyter/CLAM/grad_results/map_sample.jpg\", superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7f56e-e559-4af5-8a9a-07d68145e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_name = \"1057550\"\n",
    "slides_dir = \"WSI_IHC_J/\"\n",
    "features_dir = \"WSI_tau_j_features/h5_files/\"\n",
    "explain(resnet, model, slide_name, target_idx, features_dir, slides_dir, target_label=0)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
